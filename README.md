# GSM 8K Benchmark Evaluation

## Overview

This repository contains a Python script that evaluates the performance of  the Orca-2-7b model, provided by Microsoft, on the GSM 8K benchmark. This benchmark tests the model's capability in providing solutions to grade school math problems.

The script uses Hugging Face's `transformers` and `accelerate` libraries to load, tokenize, and generate answers for each question in the GSM 8K dataset. The output is stored in CSV files that record the model-generated answers for further analysis.

## Installation

Before running the script, ensure that you have Python installed on your system. Then, install the required dependencies by running the following command:

```bash
pip install pandas transformers accelerate torch
```

## Dataset

The GSM 8K benchmark dataset, `gsm_eval_set.csv`, should be placed in the root directory of this repository. The dataset should have a column named `question` containing the math problems to evaluate.

## Usage

The script can be executed with command-line arguments to specify the range of questions to evaluate and the compute device to use. Below is an example of how to run the script:

```bash
python evaluate_model.py --start 0 --end 100 --device cuda:0
```

### Command-line Arguments

- `-start`: The start index (inclusive) of the questions to evaluate from `gsm_eval_set.csv`.
- `-end`: The end index (exclusive) of the questions to evaluate from `gsm_eval_set.csv`.
- `-device`: The device identifier for model computations. Use `cuda:n` for GPU (where `n` is the GPU ID) or `cpu` for the CPU.

## Output

The script produces a CSV file named `Orca2_7b_GSM_Evaluation_<start>_<end>.csv` containing two columns:

- `question`: The math problem from the dataset.
- `generated_answer`: The answer generated by the model.

## Model

This evaluation uses the `microsoft/Orca-2-7b` model from Hugging Face. Make sure to have an internet connection during the first run to download the model and tokenizer.

## Custom Functions

- `inf(model, tokenizer, question, device)`: A function that takes the model, tokenizer, question, and device as inputs, then returns a tuple of the question and the answer generated by the model.

## Contributions

Contributions are welcome! Please submit pull requests with any improvements or bug fixes.

## License

The scripts and documents in this repository are provided under an open-source license. Please review the included LICENSE file for more details.

## Disclaimer

This repository and its contents are not affiliated with Microsoft or the creators of the GSM 8K benchmark dataset. This is a third-party script intended for research and educational purposes only.